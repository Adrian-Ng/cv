%-------------------------
% Resume in Latex
% Author : Sourabh Bajaj
% License : MIT
%------------------------

\documentclass[letterpaper,11pt]{article}
\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage[inline]{enumitem}
% change pdftex to tex4ht when outputting odt file!
\usepackage[pdftex]{hyperref}
\usepackage{fancyhdr}
\usepackage[symbol]{footmisc}
\usepackage{multicol}


\pagestyle{fancy}
\fancyhf{} % clear all header and footer fields
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Adjust margins
\addtolength{\oddsidemargin}{-0.375in}
\addtolength{\evensidemargin}{-0.375in}
\addtolength{\textwidth}{1in}
\addtolength{\topmargin}{-.5in}
\addtolength{\textheight}{1.0in}
% https://tex.stackexchange.com/questions/53962/why-are-urls-typeset-with-monospace-fonts-by-default
\urlstyle{same}

%%\raggedbottom
%\raggedright
\setlength{\tabcolsep}{0in}
\linespread{0.97}


% Sections formatting
\titleformat{\section}{
	\vspace{-4pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-5pt}]

%-------------------------
% Custom commands
\newcommand{\resumeItem}[3]{
	\item\small{
		\textbf{#1}\hfill\tiny{#2\\}\small{ #3 \vspace{-2pt}}
	}
}

\newcommand{\resumeSubheading}[4]{
	\vspace{-1pt}\item
	\begin{tabular*}{0.97\textwidth}{l@{\extracolsep{\fill}}r}
		\textbf{#1} & #2 \\
		\textit{\small#3} & \textit{\small #4} \\
	\end{tabular*}\vspace{-5pt}
}

\newcommand{\resumeSubItem}[3]{\resumeItem{#1}{#2}{#3}\vspace{-2pt}}

\renewcommand{\labelitemii}{$\circ$}

\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=*]}
	\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}}
	\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}
	\renewcommand{\thefootnote}{\fnsymbol{footnote}}
%-------------------------------------------
%%%%%%  CV STARTS HERE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%----------HEADING-----------------
\noindent
\Large \textbf{Adrian Ng, MSc.}
\newline
\small
Seeking Junior-Level Data Engineering Opportunities
\hfill
\begin{description*}
	\item [Email:] \href{mailto:contact@adrian.ng}{contact@adrian.ng}
	\item [Website:] \href{https://adrian.ng}{adrian.ng}
\end{description*}
%----------PROFILE-----------------
\section{Profile}
\begin{paragraph}
	I am a Computer Science graduate passionate about programming and a career in Data Engineering. I seek opportunities that meet my growing experience in \textit{Java} -- a language I have used in numerous academic projects ranging from the implementation of financial models to large-scale data processing with \textit{Apache Hadoop} and more.
	%In addition, \texttt{R} and \texttt{MATLAB} were used to implement various machine learning algorithms.
	\noindent
	\newline
	Prior to postgraduate study, my expertise in \textit{SQL development} focused on the implementation of segmentation processes for a number of clients including: \textit{Virgin Media}, \textit{TUI}, \textit{UPC}, \textit{MSD}, \textit{Volkswagen}, and \textit{KwikFit}.
	\noindent
	\newline
	After graduation, my accomplishments as a Data Analyst at \textit{Manchester City FC} leaned more towards Data Engineering, which leads me now to pursue a career in this field.
\end{paragraph}
%-----------EDUCATION-----------------
\section{Education}
\resumeSubHeadingListStart

\resumeSubheading
{Royal Holloway -- Department of Computer Science}{Sept. 2016 -- Dec. 2017}
{Master of Science in Data Science and Analytics}{with Distinction}

\resumeSubheading
{King's College London -- School of Engineering}{Sept. 2007 -- July 2010}
{Bachelor of Engineering in Mechanical Engineering}{Upper Second Class with Honours}

\resumeSubHeadingListEnd

%--------PROGRAMMING SKILLS------------
\section{Technologies}
\textbf{Languages:}
\hfill
\begin{itemize*}
	\item Java 8
	\item SQL
\end{itemize*}
\newline
\textbf{Software:}
\hfill
\begin{itemize*}
	\item IntelliJ IDEA
	\item SQL Server Management Studio
	\item Git
	\item VS Code
	\item Jira
	\item Maven
\end{itemize*}

%-----------PROJECTS-----------------
\section{Java Projects}
%\subsection{VaR}
\textbf{Implementation of Value at Risk (VaR) measure}
\hfill
\tiny
(\href{https://adrian.ng/java/var/}{https://adrian.ng/java/var/})
\hfill
(\href{https://github.com/Adrian-Ng/VaR}{https://github.com/Adrian-Ng/VaR})
\newline
\small
I implemented a number of approaches to estimating \textit{VaR}, a measure of risk, for a hypothetical investment portfolio containing stocks, options, and corresponding deltas. I utilised \textit{Google Fiance}/\textit{Yahoo Finance} APIs to read time-series data, for which I implemented a number of \textit{moving average processes} for estimating variance.
%https://tex.stackexchange.com/questions/233780/two-itemized-lists-side-by-side
\begin{multicols}{2}
	\textbf{VaR Measures}
	\begin{itemize}
		\item Model Building
		\item Historical Simulation
		\item Monte Carlo Simulation.
	\end{itemize}
	\columnbreak
	\textbf{Moving Average Processes}
	\begin{itemize}
		\item \textit{Equal Weighted}
		\item \textit{Exponentially Weighted Moving Average (EWMA)}
		\item \textit{GARCH(1,1)}
	\end{itemize}
\end{multicols}
\noindent
In addition, an implementation of the \textit{Levenberg-Marquardt} algorithm was used for optimisation of \textit{GARCH(1,1)} parameters via maximum likelihood estimation.
I made use of object-oriented techniques and patterns to accommodate these numerous approaches.
I used \texttt{Java's} concurrency APIs to parallelize the 100,000+ random walks generated by \textit{Monte Carlo} when simulating stock price movements, which resulted in a highly efficient solution.
% \newline \newline
% \noindent
% \textbf{Large-Scale data processing with Apache Hadoop}
% \hfill
% \tiny
% (\href{https://github.com/Adrian-Ng/HadoopEnron}{https://github.com/Adrian-Ng/HadoopEnron})
% \small
% \newline
% During my postgraduate module \textit{Large Scale Data Storage and Processing}, I wrote a number of \textit{MapReduce} applications. These projects included:
% \begin{itemize*}
% 	\item the aggregation of \textit{Twitter} data
% 	\item scraping a large collection of emails in the \textit{Enron Corpus}
% 	\item the extraction of nodes/edges from this communications network.
% \end{itemize*}
% I ran my applications on a self-hosted, single-node cluster as well as on the university's distributed cluster. To load/extract data in \textit{HDFS}, I used \texttt{hdfs dfs} commands.
% \begin{itemize}
% 	\item
% 	      \textbf{Apache Spark}
% 	      \hfill
% 	      \tiny
% 	      (\href{https://adrian.ng/scala/spark/enron1}{https://adrian.ng/scala/spark/enron1})
% 	      \small
% 	      \newline
% 	      In a self-learning exercise, I translated some of these \textit{MapReduce} applications to \texttt{Scala}. This code was less verbose and ran in an \textit{Apache Spark REPL}, which could still interface with \textit{HDFS} via \texttt{sparkcontext} APIs.
% \end{itemize}
\begin{description}%[style=multiline,leftmargin=3cm]
	\item[Data Mining] Building \textit{MapReduce} applications for large scale data mining and processing.
	      \begin{description}[style=multiline,leftmargin=2.5cm]
		      \item[MapReduce]
		            \begin{itemize}
			            \item aggregation of \textit{Twitter} data
			            \item scraping a large collection of emails in the \textit{Enron Corpus}
			            \item extraction of nodes/edges in communications network
		            \end{itemize}
		      \item[Hadoop]
		            \begin{itemize}
			            \item applications ran on self-hosted, single-node cluster and distributed clusters
			            \item \texttt{hdfs dfs} commands used to interface with \textit{HDFS}
		            \end{itemize}
		      \item[Spark] A subsequent self-learning exercise achieving:
		            \begin{itemize}
			            \item translation of \textit{MapReduce} applications to \texttt{Scala}, running in a \textit{Apache Spark REPL}
			            \item reduction in verbosity, maintaining interface with \textit{HDFS}
			            \item \href{https://adrian.ng/scala/spark/enron1}{https://adrian.ng/scala/spark/enron1}
		            \end{itemize}
	      \end{description}
	\item[Option Pricing]
	      Implementing numerous approaches to pricing options and their various payoffs
	      \begin{description}[style=multiline,leftmargin=2.5cm]
		      \item[Options]
		            \begin{itemize*}
			            \item Monte Carlo Simulation
			            \item Black Scholes
			            \item Binomial Trees
		            \end{itemize*}
		      \item[Payoff]
		            \begin{itemize*}
			            \item American
			            \item Asian
			            \item European
		            \end{itemize*}
	      \end{description}
	      These approaches made probabilistic assumptions, so \textit{Apache Commons Math} API was used.
	      \newline
	      \tiny
	      \href{https://adrian.ng/java/options/}{https://adrian.ng/java/options/}
	      \small
	\item[Summarizing financial data]
	      A self-taught exercise to gain familiarity with Java 8's \texttt{Stream} API. I was able to implement approaches to computing mean and variance estimates from an immutable collection of time-series financial data.
	      \hfill
	      \tiny
	      \href{https://adrian.ng/java/yahoofinance/\#stream}{https://adrian.ng/java/yahoofinance/\#stream}
	      \small


\end{description}

%		 \resumeSubItem{Google PageRank}{}
%		 {
%		   This is the implementation of Google's \textit{PageRank} algorithm. I simulate the behaviour of someone browsing a series of webpages by computing a transition matrix from an input graph and mixing a Markov Chain.
%		 }   


% %-----------COURSEWORK-----------------
% \section{Machine Learning Algorithms Implemented}
% \textbf{R}
% \hfill
% \begin{itemize*}
% 	\item k-Nearest Neighbours
% 	\item LDA
% 	\item Neural Networks
% 	\item Decision Trees
% 	\item Hierarchical Clustering
% \end{itemize*}
% \newline
% \textbf{MATLAB}
% \hfill
% \begin{itemize*}
% 	\item Hidden Markov Models
% 	\item Aggregating Algorithm
% \end{itemize*}

\newpage
%-----------EXPERIENCE-----------------
\section{Manchester City Football Club}
\textit{Data Analyst}
\hfill
\textit{Fan Relationship Management}
\hfill
\textit{Jan. - July 2018}

\begin{description}[style=multiline,leftmargin=3cm]
	\item[New York City FC Project]
	      I took ownership of this project to integrate \textit{NYCFC's} transactional and demographic data with \textit{City Football Group's} data-warehouse. This six-month project involved many phases including: discovery, engineering, and analysis. Data came from multiple external sources each with differing schema: \textit{NYCFC}, \textit{Ticketmaster} \textit{Salesforce}, \textit{Major League Soccer}.

	      \begin{description}[style=multiline,leftmargin=2.5cm]
		      \item[Data Pipeline]
		            {
		            \begin{itemize}
			            \item built pipeline ingesting data from multiple databases, replacing \textit{Informatica} solution
			            \item achived efficient ETL process via effective DML \& DDL (\texttt{OPENQUERY}, \texttt{MERGE})
		            \end{itemize}
		            }
		      \item[Data Cubes]
		            {
		            \begin{itemize}
			            \item implemented up-stream computation of drill-down/roll-up for all permutations, minimising bandwidth across distributed servers
			            \item eliminated real-time computation in \textit{Tableau} front-end, improving UX
		            \end{itemize}
		            }
		      \item[Mentoring]
		            {
		            \begin{itemize}
			            \item dedicated time to mentoring junior colleagues remotely in Manchester/New York
			            \item organised weekly workshops teaching basic DML and advanced DDL
			            \item developed additional material on my website to supplement these workshops
		            \end{itemize}
		            }
	      \end{description}
	\item[GDPR Pipeline]
	      \begin{itemize}
		      \item integrated new GDPR schema into existing datastores (\textit{SQL}, \textit{Salesforce})
		      \item worked with SQL developers to provide schema specification and UAT testing on new processes
		      \item built efficient \texttt{MERGE} process featuring relational database design
	      \end{itemize}
	\item[Customer Churn Model]
	      Modelling MCFC/NYCFC customers' future propensity to churn via \textit{logistic regression}.
	      \begin{itemize}
		      \item contributed to feature selection involving: data extraction, imputation, and normalisation
		      \item researched other models (e.g. \textit{Beta-Geometric/Beta-Bernoulli}), academic papers, \texttt{R Studio} API
	      \end{itemize}
\end{description}
\section{Creator (now Inspired Thinking Group)}
\textit{Senior CRM Campaign Executive}
\hfill
\textit{SQL Development}
\hfill
\textit{Dec. 2013 - Sept. 2016}
\begin{paragraph}
	I developed a number of \texttt{SQL} processes to transform customer data into CRM segments.  On occasion, I took responsibility for resourcing and managing the team's workload in \textit{Jira}.
\end{paragraph}
\begin{description}[style=multiline,leftmargin=3cm]
	\item[Virgin Media Segmentation]
	      \quad
	      (\href{https://adrian.ng/SQL/cte/Recursion/}{https://adrian.ng/SQL/cte/Recursion/}
	      \quad
	      (\href{https://adrian.ng/SQL/misc/openquery-xml}{https://adrian.ng/SQL/misc/openquery-xml})
	      \small
	      \begin{itemize}
		      \item built a bespoke import tool around \texttt{BULK INSERT} to ingest millions of tuples distributed across multiple flat-files
		      \item achieved efficient joining of local and remote data by  combining \texttt{OPENQUERY}, \texttt{XML}, and dynamic \texttt{SQL}
		      \item implemented efficient regex parsing via recursion (operating akin to \texttt{flatMap} in \texttt{Java 8}/\texttt{Scala})
	      \end{itemize}
	\item[Volkswagen Onboarding]
	      \begin{itemize}
		      \item built and tested a new segmentation process for broadcasting email \textit{and} SMS.
		      \item provided schema specification to developers for data warehousing
	      \end{itemize}
	\item[TUI Redesign]
	      \begin{itemize}
		      \item worked closely with TUI to integrate a new, responsive design of their \textit{Thomson} and \textit{First Choice} large deployment broadcasts (5M+ recipients)
		      \item wrote \texttt{TCL} scripts for dynamic \texttt{HTML} merges and gained efficiencies by moving expensive operations upstream
		      \item gained recognition with client and was awarded at the end of this three-month project
	      \end{itemize}
\end{description}

\section{Seatwave (now Ticketmaster)}
\textit{Marketing Analyst Intern}
\hfill
\textit{Commercial Team}
\hfill
\textit{May 2013 - Dec. 2013\\}

\noindent
Using \textit{SQL Server Management Studio}, I wrote DML capable of querying the transactional/customer databases to return data for warehousing, reporting, and segmentation. I also worked on pricing and spatial analyses, using \textit{QGIS} as a visualisation tool.
\end{document}